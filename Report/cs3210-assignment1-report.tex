\documentclass[a4paper,12pt]{article}


\usepackage{minted}
\usepackage[cm]{fullpage}
%\usepackage[a4paper,margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{capt-of}

\setminted[C]{fontsize=\small, tabsize=4, breaklines, linenos}
\setminted[Ruby]{fontsize=\small, tabsize=4, breaklines, linenos}
\setminted[text]{fontsize=\small, tabsize=4, breaklines, linenos}

%\setlength\parindent{0pt}

\title{Assignment 1 Report}
\author{Julius Putra Tanu Setiaji (A0149787E), Chen Shaowei (A0110560Y)}
\date{24 October 2018}

\begin{document}
\maketitle

\section{Program Design}
This train simulation is implemented in OpenMPI. Primary design considerations are:
\begin{itemize}
  \item Each edge is simulated by one process as required in the specifications.
  \item There is a master process responsible for the following:
    \begin{itemize}
      \item Distribution of information (map, lines) to slave processes.
      \item Keeping track of train states (travelling/stationary).
      \item Keeping track of station door open/close times.
      \item Synchronising time across all slaves.
    \end{itemize}
  \item Slave processes hold queues of trains and send them to each other.
\end{itemize}

\subsection*{Assumptions}

\begin{itemize}
	\item Only one train can open its doors at each at any one time, regardless of direction.
	\item Train stations have infinite capacity for waiting trains.
	\item Time units are discrete and can have no subdivisions
	      \begin{itemize}
		      \item \textbf{Implication}: It is sufficient to store all time units as integers instead of floating point numbers
	      \end{itemize}
	\item Trains must open their doors for at least 1 unit of time.
	      \begin{itemize}
		      \item \textbf{Implication}: We round every randomly generated door open time up to the nearest integer
	      \end{itemize}
\end{itemize}

\section{Points to Note / Implementation Details}
\begin{itemize}
	\item Current simulation time needs to be shared across all processes. In addition, time can only be advanced after all threads have completed the actions to be done in the current tick.
    \begin{itemize}
      \item \textbf{Implication}: Explicit synchronisation messages need to be sent between master and slaves before and after the advancement of time.
    \end{itemize}
  \item Each slave process maintains two queues of trains. The first queue contains the trains that are waiting to enter the edge. The second queue contains the trains that are waiting at the next station but have yet to close their doors.
  \item The logic for each slave process at each tick is as follows:
    \begin{itemize}
      \item If a current train is occupying the edge and it can leave at the current time, the process will query master to find out when this train will finish closing its doors. The edge will then be marked as available.
      \item If there are trains waiting to access the edge, the process will dequeue the first one and set it as the current train.
      \item

    \end{itemize}
	\item Each train is a finite state machine with 4 states: \texttt{OPEN\_DOOR}, \texttt{CLOSE\_DOOR}, \texttt{DEPART} and \texttt{ARRIVE}.
	\item Each train keeps track of its next action time (time for it to change to the next state), and actions to be completed within the current tick are performed in a \mintinline{C}{while} loop.
	\item There is a \mintinline{C}{#pragma omp barrier} to ensure that all threads exit the \mintinline{C}{while} loop before time is advanced.
	\item The advancement of time is done in a \mintinline{C}{#pragma omp single} block to ensure that it is only performed by one thread. In addition, \mintinline{C}{#pragma omp single} has an implicit barrier at the end of the block so this prevents other threads from entering the next iteration of the \mintinline{C}{while} loop until the advancement of time is complete.
	\item Certain resources i.e. train tracks, door-opening rights are limited, and only one train may access them at any time.
	      \begin{enumerate}
		      \item One way to implement this is to have threads block when waiting to access such resources. However, this would interfere with the way we have chosen to implement time within this simulation. Blocked threads would prevent code after a \mintinline{C}{#pragma omp barrier} statement from being executed. We therefore decided \textbf{not} to go with this implementation.
		      \item An alternative way to implement is to have a queue of trains requesting access to such resources. At each tick, each train would check whether it is at the head of the queue, and if so, it will be able to access the resource. We realised that it will also be necessary to store the time at which a train would be able to gain access to the resource, since our simulation time advances in integer increments, but door open time may have a fractional value. Upon further consideration, we realised that this design could be simplified.
		      \item The key insight we arrived at is that any train waiting for access to a resource only needs to know the next time said resource will be available. Since this system does not permit a train to give up waiting for a resource, this can be implemented simply with a thread-safe timekeeper object. When a train requests access to a resource, it tells the timekeeper how much time it will occupy the resource for. The timekeeper will then inform the train of the time when the train can access the resource, and update its internal next available time. This is the implementation we decided to go with. In other words, we are implementing an implicit queue for a First-Come-First-Serve (FCFS) scheduling policy.
	      \end{enumerate}
	\item The next consideration is ensuring that system statistics are reported correctly. Since we assume that trains cannot open its doors for 0s, only one train can open its doors at each station per tick. There is therefore no potential race condition in the update of statistics. Nevertheless, we protected their critical sections with a \mintinline{C}{#pragma omp critical} block for additional safety.
	\item Since print statements are not atomic, we wrapped them in a \mintinline{C}{#pragma omp critical} block to ensure that only one print operation executes at any one time.
	\item Thread safe timekeeper objects have their critical sections protected by a \mintinline{C}{#pragma omp critical} block.
\end{itemize}

\section{Execution Time}

\subsection{Testcase Used}
We use a map generated by a Ruby script which can be found in appendix. The map generated will have at least 4 vertices with degree = 1, and all the paths forming the train lines are at least of length 4. However, these values are configurable.

We ran the same map for 100, 1000, and 10000 time-ticks with all possible different combinations of numbers of trains in each line as long as the total number of trains is between 1 and 64 inclusive. This results in around 47,900 testcases for each time-tick size. As such, we will only include the scatter diagram of the results in the report. However, should the need arise, csv files containing the raw data is attached together with the report.

Below you can find a sample input and visualisation of the adjacency matrix and the train lines. The parameters that we used are number of stations = 10, maximum distance between stations = 10.

Do also note that to facilitate more accurate execution time analysis, we disabled per-tick status output for the following tests.

% \begin{center}
% 	\captionof{figure}{Sample Input}
% 	\begin{minted}{text}
% 10
% Somerset,Tan Kah Kee,Redhill,Sembawang,Riviera,Samudera,Sengkang,Boon Lay,Tampines West,Tampines
% 0 0 0 0 0 0 0 0 6 0
% 0 0 1 0 0 0 1 0 4 1
% 0 1 0 0 6 0 0 0 0 0
% 0 0 0 0 0 0 0 4 0 9
% 0 0 6 0 0 0 0 0 0 0
% 0 0 0 0 0 0 0 0 0 10
% 0 1 0 0 0 0 0 0 0 0
% 0 0 0 4 0 0 0 0 0 0
% 6 4 0 0 0 0 0 0 0 0
% 0 1 0 9 0 10 0 0 0 0
% 0.1,0.2,0.1,0.1,1.0,0.5,0.7,0.8,0.5,0.5
% Somerset,Tampines West,Tan Kah Kee,Tampines,Sembawang,Boon Lay
% Samudera,Tampines,Tan Kah Kee,Sengkang
% Somerset,Tampines West,Tan Kah Kee,Sengkang
% 10000
% 21,22,21
% 		\end{minted}
% \end{center}

% \begin{center}
% 	\captionof{figure}{Map of the train line used, with the 3 lines indicated}
% 	\includegraphics[width=0.5\linewidth]{map}
% \end{center}

% \newpage
% \subsection{Graphs}
% Extreme outliers were removed from the scatter diagram.
% \begin{center}
% 	\captionof{figure}{Execution Time for 100 ticks}
% 	\centering
% 	\includegraphics[width=\linewidth]{100-time}
% \end{center}
% \begin{center}
% 	\captionof{figure}{Execution Time for 1,000 ticks}
% 	\centering
% 	\includegraphics[width=\linewidth]{1000-time}
% \end{center}
% \begin{center}
% 	\captionof{figure}{Execution Time for 10,000 ticks}
% 	\centering
% 	\includegraphics[width=\linewidth]{10000-time}
% \end{center}

\section{Discussion}
It can be observed that the wall clock time taken for the simulation to complete increases as number of threads increases. This is because as number of threads increases, there is more contention of resources -- in our case contention for each train (thread) in using links (edges) between stations (vertices) and contention for each train in opening door at each station. We are managing this using an implicit queue through implementing a timekeeper to track the next allowed event to occur, protected by marking that section as critical. As such, for each link (edge) or station (vertex), only one train (thread) is able to register itself to the timekeeper at any given time -- others will have to wait.

However, we have an interesting observation as well. Notice that the execution time behaves very differently when the number of threads is beyond the number of logical cores (20 cores). For small input size (100 ticks), when the number of threads is beyond the number of logical cores, the execution time actually falls. However, as input size gets larger (1,000 and 10,000 ticks), execution time increases. This can be explained that when the number of threads are below the number of logical cores, all the threads are running concurrently, resulting in more lock contention (not to be confused with resource contention). However, when number of threads is above the number of logical cores, the threads take turns to wake up and do work, resulting in less lock contention. For smaller input size, the lock contention time actually outweighs the execution time, resulting in the fall in execution time. However, for larger input size, there is a large overhead in context-switching which outweighs the effect of lock contention time. This is supported by the data we collected on number of context-switches for 100 ticks and 1,000 ticks.

We also observe another trend -- that the variance in execution time falls when the number of threads exceed the number of logical cores. We currently have no explanation on this, but we suspect that the compiler does an optimisation when the number of threads exceed the number of logical cores.

% \newpage
% \begin{center}
% 	\captionof{figure}{Number of context switches for 100 ticks}
% 	\includegraphics[width=0.9\linewidth]{100-cs}
% \end{center}
% \begin{center}
% 	\captionof{figure}{Number of context switches for 1,000 ticks}
% 	\includegraphics[width=0.9\linewidth]{1000-cs}
% \end{center}

\section{Bonus}
Starvation will never occur in the simulation program that we wrote. This is because to decide which train to open door or to be allowed to use a link next, we are using an implicit queue to implement First-Come-First-Serve (FCFS) scheduler. As such, every train is assured access to the link or permission to open door after a long enough time. The assumptions are that no train open its doors or travel using the links indefinitely (which we believe are fair to make).

\newpage
\section{Appendix A: Ruby script used to generate test cases}
Below is the code listing of the ruby script used to generate test cases. Essentially, it does:
\begin{enumerate}
	\item Create a random adjacency matrix with diagonal = 0
	\item Find the MST of the random graph created
	\item Ensure that there are enough vertices with degree = 1, else go back to step 1
	\item Enumerate the 2-combinations of the vertices with degree = 1, and pick 3 randomly.
	\item For each of the three 2-combinations, assign them to be the termini of each line.
	\item Using breadth-first-search, find the path between the two vertices for each pair of termini.
	\item Ensure that the path is long enough, else go back to step 4.
\end{enumerate}
\begin{minted}{Ruby}

  # SOME CODE

	\end{minted}
\end{document}